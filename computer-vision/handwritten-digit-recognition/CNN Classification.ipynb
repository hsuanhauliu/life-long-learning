{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwritten Digit Classification with CNN\n",
    "This notebook shows how to use a simple convolutional neural network to do image classification. The notebook was written for practice and the original codes were taken from this [tutorial](https://machinelearningmastery.com/handwritten-digit-recognition-using-convolutional-neural-networks-python-keras/).\n",
    "\n",
    "Read more about Keras [here](https://keras.io/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load the MNIST dataset using a function provided by Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset features shape: (60000, 28, 28)\n",
      "Train dataset labels shape: (60000,)\n",
      "Test dataset features shape: (10000, 28, 28)\n",
      "Test dataset labels shape: (10000,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "print(f'Train dataset features shape: {train_images.shape}')\n",
    "print(f'Train dataset labels shape: {train_labels.shape}')\n",
    "print(f'Test dataset features shape: {test_images.shape}')\n",
    "print(f'Test dataset labels shape: {test_labels.shape}')\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.imshow(train_images[0], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(222)\n",
    "plt.imshow(train_images[1], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(223)\n",
    "plt.imshow(train_images[2], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(224)\n",
    "plt.imshow(train_images[3], cmap=plt.get_cmap('gray'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional layer requires the inputs to be 4D, in the format of either [batch]x[channels]x[rows]x[columns] or [batch]x[rows]x[columns]x[channels]. The default is set to 'channel_last', which is the latter. Since the images in MNIST are in grey-scale, there is only going to be one channel for the input images. Batch represents how many images there are in the dataset for the input layer.\n",
    "\n",
    "You can read more about how Keras' convolutional layer works [here](https://keras.io/layers/convolutional/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "test_x = test_images.reshape(test_images.shape[0], 28, 28, 1).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also normalize the data, as well as one-shot encode the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x / 255\n",
    "test_x = test_x / 255\n",
    "\n",
    "train_y = np_utils.to_categorical(train_labels)\n",
    "test_y = np_utils.to_categorical(test_labels)\n",
    "num_classes = test_y.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's define our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=32, kernel_size=(5, 5), input_shape=(28, 28, 1), data_format='channels_last', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the data and the model, we can start the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 131s - loss: 0.2386 - acc: 0.9292 - val_loss: 0.0743 - val_acc: 0.9773\n",
      "Epoch 2/10\n",
      " - 130s - loss: 0.0763 - acc: 0.9762 - val_loss: 0.0486 - val_acc: 0.9840\n",
      "Epoch 3/10\n",
      " - 132s - loss: 0.0542 - acc: 0.9827 - val_loss: 0.0403 - val_acc: 0.9877\n",
      "Epoch 4/10\n",
      " - 126s - loss: 0.0417 - acc: 0.9871 - val_loss: 0.0374 - val_acc: 0.9883\n",
      "Epoch 5/10\n",
      " - 127s - loss: 0.0346 - acc: 0.9891 - val_loss: 0.0327 - val_acc: 0.9908\n",
      "Epoch 6/10\n",
      " - 127s - loss: 0.0275 - acc: 0.9913 - val_loss: 0.0360 - val_acc: 0.9889\n",
      "Epoch 7/10\n",
      " - 116s - loss: 0.0245 - acc: 0.9919 - val_loss: 0.0378 - val_acc: 0.9880\n",
      "Epoch 8/10\n",
      " - 127s - loss: 0.0201 - acc: 0.9935 - val_loss: 0.0293 - val_acc: 0.9909\n",
      "Epoch 9/10\n",
      " - 119s - loss: 0.0166 - acc: 0.9944 - val_loss: 0.0462 - val_acc: 0.9857\n",
      "Epoch 10/10\n",
      " - 121s - loss: 0.0147 - acc: 0.9953 - val_loss: 0.0316 - val_acc: 0.9900\n",
      "Error Rate: 1.00%\n"
     ]
    }
   ],
   "source": [
    "model = classification_model()\n",
    "model.fit(train_x, train_y, validation_data=(test_x, test_y), epochs=10, batch_size=200, verbose=2)\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "print('Error Rate: {0:.2f}%'.format(100 - scores[1] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can use the trained model to do predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs = model.predict(test_x)\n",
    "pred_labels = np.argmax(pred_probs, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomly pick an image from the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: 8\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_test = test_images.shape[0]\n",
    "rand_index = np.random.randint(num_test)\n",
    "print(f'Predicted label: {pred_labels[rand_index]}')\n",
    "\n",
    "plt.imshow(test_images[rand_index])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test a larger network to see if we can get a better result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def larger_classification_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(30, (5, 5), input_shape=(28, 28, 1), data_format='channels_last', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(15, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 112s - loss: 0.4664 - acc: 0.8562 - val_loss: 0.1484 - val_acc: 0.9541\n",
      "Epoch 2/10\n",
      " - 119s - loss: 0.1535 - acc: 0.9531 - val_loss: 0.0892 - val_acc: 0.9725\n",
      "Epoch 3/10\n",
      " - 113s - loss: 0.1069 - acc: 0.9674 - val_loss: 0.0685 - val_acc: 0.9783\n",
      "Epoch 4/10\n",
      " - 110s - loss: 0.0836 - acc: 0.9743 - val_loss: 0.0603 - val_acc: 0.9816\n",
      "Epoch 5/10\n",
      " - 110s - loss: 0.0693 - acc: 0.9784 - val_loss: 0.0469 - val_acc: 0.9845\n",
      "Epoch 6/10\n",
      " - 111s - loss: 0.0605 - acc: 0.9810 - val_loss: 0.0509 - val_acc: 0.9838\n",
      "Epoch 7/10\n",
      " - 111s - loss: 0.0547 - acc: 0.9825 - val_loss: 0.0463 - val_acc: 0.9839\n",
      "Epoch 8/10\n",
      " - 114s - loss: 0.0491 - acc: 0.9842 - val_loss: 0.0380 - val_acc: 0.9867\n",
      "Epoch 9/10\n",
      " - 113s - loss: 0.0446 - acc: 0.9858 - val_loss: 0.0406 - val_acc: 0.9870\n",
      "Epoch 10/10\n",
      " - 110s - loss: 0.0406 - acc: 0.9872 - val_loss: 0.0393 - val_acc: 0.9863\n",
      "Error Rate: 1.37%\n"
     ]
    }
   ],
   "source": [
    "model_2 = larger_classification_model()\n",
    "model_2.fit(train_x, train_y, validation_data=(test_x, test_y), epochs=10, batch_size=200, verbose=2)\n",
    "scores = model_2.evaluate(test_x, test_y, verbose=0)\n",
    "print('Error Rate: {0:.2f}%'.format(100 - scores[1] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that the second model actually has higher error rate than the previous one. There are many optimization techniques that we could use to improve a network's performance that we have not used here. From observation, it seems that a simply network is enough to classify MNIST images pretty well. As the features and classification task grow more complex (i.e. larger number of labels and complicated objects), we will need more larger network to achieve high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
